{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540e7f49",
   "metadata": {},
   "source": [
    "# 数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ef266",
   "metadata": {},
   "source": [
    "数据集类型是微博情感分类 \n",
    "\n",
    "来源https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/weibo_senti_100k/intro.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab231cb",
   "metadata": {},
   "source": [
    "# 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5e690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "0.1.4\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from nlp_basictasks.tasks import cls\n",
    "from nlp_basictasks.evaluation import clsEvaluator\n",
    "from nlp_basictasks.readers.cls import getExamplesFromData\n",
    "import nlp_basictasks\n",
    "print(nlp_basictasks.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b3833",
   "metadata": {},
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cebfab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数目（总体）：119988\n",
      "评论数目（正向）：59993\n",
      "评论数目（负向）：59995\n"
     ]
    }
   ],
   "source": [
    "data_path='/data/nfs14/nfs/aisearch/asr/xhsun/datasets/weibo_senti_100k.csv'\n",
    "pd_all = pd.read_csv(data_path)\n",
    "\n",
    "print('评论数目（总体）：%d' % pd_all.shape[0])\n",
    "print('评论数目（正向）：%d' % pd_all[pd_all.label==1].shape[0])\n",
    "print('评论数目（负向）：%d' % pd_all[pd_all.label==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc368d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>1</td>\n",
       "      <td>霾都欢迎你再来。。。。。。[嘻嘻]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40365</th>\n",
       "      <td>1</td>\n",
       "      <td>据说花名叫＂大烟桐＂，不知是否准确。 //@刘道勇oO:继续求助//@医生passerby:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>1</td>\n",
       "      <td>当马栏坡坡姐遇上新加坡坡姐[嘻嘻] ！笑料一波又一波，颇有看点！@谢娜 这个动作@孙燕姿 要...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84373</th>\n",
       "      <td>0</td>\n",
       "      <td>看着也还行//@小四爱世博: 李伯祥，赵伟洲我都爱看，刘兰芳作为开奖嘉宾，不解??? //@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70913</th>\n",
       "      <td>0</td>\n",
       "      <td>我真有[失望][耶]//@全球奇事趣闻:我希望我可以选择性失忆。[心]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93627</th>\n",
       "      <td>0</td>\n",
       "      <td>人在中山，对话厉无畏先生。来去匆匆，没吃到中山乳鸽，有些伤感。[失望]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>1</td>\n",
       "      <td>哥，你一点儿不老，在我眼中你就是一帅小伙儿[嘻嘻]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68049</th>\n",
       "      <td>0</td>\n",
       "      <td>傻逼联通3G,下班高峰期地铁一号线，十号线完全上不了网，就尼玛会吹3G速度比移动快，移动在地...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24206</th>\n",
       "      <td>1</td>\n",
       "      <td>回复@很靠谱的叁个六:哈哈，给你留一本呢。我签的名，你看咋样？[哈哈] //@很靠谱的叁个六...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54556</th>\n",
       "      <td>1</td>\n",
       "      <td>[爱你]哇！超级浪漫啊！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20792</th>\n",
       "      <td>1</td>\n",
       "      <td>王总老那么帅[酷] //@王端0909:＂帅＂就一个字 [威武][给力][鼓掌][耶]//@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63302</th>\n",
       "      <td>0</td>\n",
       "      <td>11.11是快递员的末日。。。[泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>1</td>\n",
       "      <td>元宵快乐！今天你赏灯了没？吃元宵了没？[嘻嘻]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81598</th>\n",
       "      <td>0</td>\n",
       "      <td>今天cei了一个小壶，难道是黑色星期五还是诸事不宜的大凶日[泪]败一败姑姑的爷爷求保佑@su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58228</th>\n",
       "      <td>1</td>\n",
       "      <td>你想找我干嘛？[花心][太开心][亲亲][害羞]，人家不好意思啦[嘻嘻][哈哈][嘻嘻][哈哈]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>1</td>\n",
       "      <td>今天不晓得算不算好运，由于要等领导走后才能走点掐的很紧！到火车站还要取票排队进站，到中门检票...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80750</th>\n",
       "      <td>0</td>\n",
       "      <td>我们还能安全多久。。。//@中???王??：中??道??的信?系?，究竟??藏多少致命危?？...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87980</th>\n",
       "      <td>0</td>\n",
       "      <td>#带着微博去旅行#一个凉字都不能形容六盘水的夏天了，大清早起来，我感觉到的是冷。此次行程带的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66914</th>\n",
       "      <td>0</td>\n",
       "      <td>把车钥匙锁在后备箱，备用钥匙在家里，家门钥匙在车里！这种死循环可还行....开车300，开家...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21299</th>\n",
       "      <td>1</td>\n",
       "      <td>缘分呐 //@哈困那维塔塔:bali bali改名  //@酱鸭腿走运了:矮油 不要那么直接...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                             review\n",
       "3032       1                                  霾都欢迎你再来。。。。。。[嘻嘻]\n",
       "40365      1  据说花名叫＂大烟桐＂，不知是否准确。 //@刘道勇oO:继续求助//@医生passerby:...\n",
       "2413       1  当马栏坡坡姐遇上新加坡坡姐[嘻嘻] ！笑料一波又一波，颇有看点！@谢娜 这个动作@孙燕姿 要...\n",
       "84373      0  看着也还行//@小四爱世博: 李伯祥，赵伟洲我都爱看，刘兰芳作为开奖嘉宾，不解??? //@...\n",
       "70913      0                我真有[失望][耶]//@全球奇事趣闻:我希望我可以选择性失忆。[心]\n",
       "93627      0                人在中山，对话厉无畏先生。来去匆匆，没吃到中山乳鸽，有些伤感。[失望]\n",
       "3085       1                          哥，你一点儿不老，在我眼中你就是一帅小伙儿[嘻嘻]\n",
       "68049      0  傻逼联通3G,下班高峰期地铁一号线，十号线完全上不了网，就尼玛会吹3G速度比移动快，移动在地...\n",
       "24206      1  回复@很靠谱的叁个六:哈哈，给你留一本呢。我签的名，你看咋样？[哈哈] //@很靠谱的叁个六...\n",
       "54556      1                                       [爱你]哇！超级浪漫啊！\n",
       "20792      1  王总老那么帅[酷] //@王端0909:＂帅＂就一个字 [威武][给力][鼓掌][耶]//@...\n",
       "63302      0                                 11.11是快递员的末日。。。[泪]\n",
       "6063       1                            元宵快乐！今天你赏灯了没？吃元宵了没？[嘻嘻]\n",
       "81598      0  今天cei了一个小壶，难道是黑色星期五还是诸事不宜的大凶日[泪]败一败姑姑的爷爷求保佑@su...\n",
       "58228      1   你想找我干嘛？[花心][太开心][亲亲][害羞]，人家不好意思啦[嘻嘻][哈哈][嘻嘻][哈哈]\n",
       "2482       1  今天不晓得算不算好运，由于要等领导走后才能走点掐的很紧！到火车站还要取票排队进站，到中门检票...\n",
       "80750      0  我们还能安全多久。。。//@中???王??：中??道??的信?系?，究竟??藏多少致命危?？...\n",
       "87980      0  #带着微博去旅行#一个凉字都不能形容六盘水的夏天了，大清早起来，我感觉到的是冷。此次行程带的...\n",
       "66914      0  把车钥匙锁在后备箱，备用钥匙在家里，家门钥匙在车里！这种死循环可还行....开车300，开家...\n",
       "21299      1  缘分呐 //@哈困那维塔塔:bali bali改名  //@酱鸭腿走运了:矮油 不要那么直接..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_all.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f878a71",
   "metadata": {},
   "source": [
    "## 打乱数据集，同时划分训练、验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94faee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119988\n"
     ]
    }
   ],
   "source": [
    "print(len(pd_all))\n",
    "random_idx=np.random.permutation(len(pd_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e976976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 20000\n"
     ]
    }
   ],
   "source": [
    "#时间关系仅取前20000个作为训练\n",
    "sentences=pd_all['review'].values[random_idx].tolist()[:20000]\n",
    "labels=pd_all['label'].values[random_idx].tolist()[:20000]\n",
    "print(len(sentences),len(labels))\n",
    "random_idx=np.random.permutation(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a559f866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 128 : *****************************Logging some train examples*****************************\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 129 : Total train nums is : 16000\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "体育馆，爽啊！！[哈哈][哈哈][哈哈][哈哈][哈哈][哈哈][哈哈][哈哈]\t1\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "正在看@蒋蒋韵  主笔的@韩庚 专访，欣赏ing[鼓掌]@韩庚粉丝团-江苏 @韩庚吧 @韩庚歌友会官方 @王者韩庚论坛   可买这期杂志看看[呵呵]\t1\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "我们这边都不纪念了[晕]其实很可惜，很好回顾历史，推广战地旅游的机会[汗]\t0\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "[鼓掌] //@峤九一://@南多酱:壮哉我大成都！{只转不看，看了要哭！[可怜]} //@Just__We://@枣子_求警花给条活路:壮哉我大天府吃货帝国！\t1\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "这次的周末驾到去中蒙边境[嘻嘻]\t1\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 128 : *****************************Logging some dev examples*****************************\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 129 : Total dev nums is : 4000\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "最亲爱的“八女”们，@老焦爱民 焦总盛情邀请大家参加新片《亲密敌人》于18日的首映。请能出席的姐妹儿们回复我，以便我统计最终人数。@白杨白小杨 @恺恺就姓乐 @西啦啦1 @秋阳硕硕 @年画真豆 @钢蛋元元  @橘ju @Lillian风之花 还有没有@到的几位… C组O恺总受累组织下了！[爱你]\t1\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "我家小哈的流氓睡姿[威武][哈哈][花心]\t1\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "[偷笑]//@吴群吴群:在深山中，有同志告诉我，说您又说我没准谱了，?一定进山赴约，我突然发?竟有些想您，必须得约您喝酒了！陪酒者@双鱼之渔 @布鲁诺白 @李小俗 @大胡子梦露 @李泗 @疯柜来的人 //@老匹夫之勇:可以约看一下  //@李小俗:这个时候真想有辆车……就不用怕晚上回不去家了……[泪]\t0\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "好样的 果子的片一样狠毒 我喜欢[威武][给力][哈哈]\t1\n",
      "2021-08-24 19:42:44 - INFO - getExamplesFromData - 132 : \n",
      "陪安妮看书中，忽然小朋友认真的盯住其中一页的图片后抬起头认真的问我：这两只非（灰）色的小马的眼睛肿么没有哇?     [晕]\t0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "label2id={'0':0,'1':1}\n",
    "dev_ratio=0.2#训练集的20%作为验证\n",
    "dev_nums=int(len(sentences)*dev_ratio)\n",
    "train_nums=len(sentences)-dev_nums\n",
    "print(dev_nums)\n",
    "train_sentences=sentences[:train_nums]\n",
    "train_labels=labels[:train_nums]\n",
    "dev_sentences=sentences[-dev_nums:]\n",
    "dev_labels=labels[-dev_nums:]\n",
    "train_examples,max_seq_len=getExamplesFromData(sentences=train_sentences,labels=train_labels,label2id=label2id,mode='train',return_max_len=True)\n",
    "dev_examples=getExamplesFromData(sentences=dev_sentences,labels=dev_labels,label2id=label2id,mode='dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ac4b5",
   "metadata": {},
   "source": [
    "# 定义路径加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e279b21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:43:49 - INFO - __init__ - 48 : The label2id is\n",
      " {\"0\": 0, \"1\": 1}\n",
      "2021-08-24 19:43:49 - INFO - __init__ - 58 : Loading model from /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/, which is from huggingface model\n",
      "2021-08-24 19:43:49 - INFO - get_config_dict - 177 : loading configuration file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/config.json\n",
      "2021-08-24 19:43:49 - INFO - from_pretrained - 404 : loading bert model file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/\n",
      "2021-08-24 19:43:49 - INFO - from_pretrained - 423 : BertConfig has been loaded from /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:43:51 - INFO - from_pretrained - 125 : loading vocabulary file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "#max_seq_len就是训练集中最长的句子长度\n",
    "model_path='/data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/'\n",
    "print(max_seq_len)\n",
    "max_seq_len=min(512,max_seq_len)\n",
    "cls_model=cls(model_path=model_path,label2id=label2id,max_seq_length=max_seq_len,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603f5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=32\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b9f49",
   "metadata": {},
   "source": [
    "# 定义evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943fd154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:44:28 - INFO - __init__ - 28 : label2id like : {'0': 0, '1': 1}\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 39 : The number of 0 in dataset is 2020\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 39 : The number of 1 in dataset is 1980\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 45 : Evalautor sentence like : \n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : [衰] //@中原网:【图片中的“海市蜃楼”系周边建筑】有结果啦，虚惊一场，有多位网友向小编反映，下午的时候这个点经过该路口，并未发现有“海市蜃楼”现象出现，图片上的“海市蜃楼”应该是对面的建筑（经现场核实，系附近一楼盘）反射在玻璃板上，正好被拍下来了，拍摄者当时可能坐在公交车里拍的。\t0\n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : @一辰 ，尼玛太有才了[cai正呀] [哈哈] @隋杨\t1\n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : 小伙伴儿们现在拿起手机，打开微博客户端-广场，双节有惊喜呦！[吃元宵][moc亲吻]//@兰亦兰: [蜡烛][泪]//@我不是蛐蛐: [哈哈] //@郭宏:转发微博\t1\n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : 我们饮中八仙也郑重承诺 剩下的画展 我们必须都去 哈哈//@大匠之门李笑天: 回复@八年小散:我郑重诚诺。要在中国美术办它10次画展[嘻嘻][嘻嘻] //@八年小散:还有听见此话的吗？ //@大匠之门李笑天:[嘻嘻][嘻嘻][威武] //@郭月晨:这个我听见了 //@苗雪珊: [可爱]真滴嘛\t1\n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : [蜡烛][蜡烛][蜡烛]求报复社会的人们放过无辜老百姓吧[伤心][伤心][伤心]\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator=clsEvaluator(sentences=dev_sentences,label_ids=dev_labels,write_csv=False,label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e98e64",
   "metadata": {},
   "source": [
    "# 训练模型\n",
    "- is_pairs用来指明是单句子分类任务还是双句子分类任务\n",
    "- output_path是保存模型的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdede3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:45:35 - INFO - fit - 102 : 当前是单句子分类任务\n",
      "2021-08-24 19:45:35 - INFO - fit - 113 : 一个epoch 下，每隔100个step会输出一次loss，每隔250个step会评估一次模型\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20bc0be763d4e89be784039cd6de085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0433a587b05449d28fe61990f29604df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:45:43 - INFO - __call__ - 63 : ClsEvaluator: Evaluating the model on  dataset in epoch 0 after 1 steps:\n",
      "2021-08-24 19:45:43 - INFO - predict - 221 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45353ed454b141ef93c78171118a053c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:49:18 - INFO - __call__ - 70 : Accuracy: 0.436\n",
      "2021-08-24 19:49:18 - INFO - __call__ - 82 : 0\tprecision : 0.450293, recall : 0.529205,  f1 score : 0.481653\n",
      "2021-08-24 19:49:18 - INFO - __call__ - 82 : 1\tprecision : 0.415127, recall : 0.340907,  f1 score : 0.369487\n",
      "2021-08-24 19:49:18 - INFO - __call__ - 93 : AUC: 0.404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:49:20 - INFO - save_pretrained - 509 : Model weights saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/pytorch_model.bin\n",
      "2021-08-24 19:49:20 - INFO - save_pretrained - 150 : Configuration saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-24 19:49:20 - INFO - save_vocab - 51 : Vocab saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-24 19:49:20 - INFO - fit - 188 : In epoch 0, training_step 0, the eval score is 0.403772502250225, previous eval score is -9999999, model has been saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\n",
      "2021-08-24 20:00:12 - INFO - fit - 166 : Epoch : 0, train_step : 100/500, loss_value : 0.341104484423995 \n",
      "2021-08-24 20:10:16 - INFO - fit - 166 : Epoch : 0, train_step : 200/500, loss_value : 0.06391732832184062 \n",
      "2021-08-24 20:15:35 - INFO - __call__ - 63 : ClsEvaluator: Evaluating the model on  dataset in epoch 0 after 251 steps:\n",
      "2021-08-24 20:15:35 - INFO - predict - 221 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc071c9f33842c691c4685d5de602cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 20:18:48 - INFO - __call__ - 70 : Accuracy: 0.981\n",
      "2021-08-24 20:18:48 - INFO - __call__ - 82 : 0\tprecision : 0.965529, recall : 0.998510,  f1 score : 0.976769\n",
      "2021-08-24 20:18:48 - INFO - __call__ - 82 : 1\tprecision : 0.998425, recall : 0.963631,  f1 score : 0.975747\n",
      "2021-08-24 20:18:48 - INFO - __call__ - 93 : AUC: 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 20:18:55 - INFO - save_pretrained - 509 : Model weights saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/pytorch_model.bin\n",
      "2021-08-24 20:18:55 - INFO - save_pretrained - 150 : Configuration saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-24 20:18:55 - INFO - save_vocab - 51 : Vocab saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-24 20:18:55 - INFO - fit - 188 : In epoch 0, training_step 250, the eval score is 0.9983108310831084, previous eval score is 0.403772502250225, model has been saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\n",
      "2021-08-24 20:23:54 - INFO - fit - 166 : Epoch : 0, train_step : 300/500, loss_value : 0.04959781204350293 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5652511f0b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/tasks/cls.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, is_pairs, train_dataloader, evaluator, epochs, loss_fct, scheduler, warmup_proportion, optimizer_type, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, early_stop_patience, print_loss_step, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mskip_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mscale_before_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                     \u001b[0mloss_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#CrossEntropyLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mtraining_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/heads/cls.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, label_ids, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         '''\n\u001b[0;32m---> 97\u001b[0;31m         (sequence_outputs,pooled_output)=self.bert(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     98\u001b[0m                                                   \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                                                    \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/modules/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         encoded_layers = self.encoder(embedding_output,\n\u001b[0m\u001b[1;32m    586\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                                       output_all_encoded_layers=output_all_encoded_layers)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/modules/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/modules/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/modules/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cls_model.fit(is_pairs=False,train_dataloader=train_dataloader,evaluator=evaluator,output_path=\"/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255a9cd",
   "metadata": {},
   "source": [
    "**时间关系暂停训练**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad830e",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6ad4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 20:29:10 - INFO - predict - 221 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236f27bac0074547b393155825eda7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.00504928 0.9949508 ]\n",
      " [0.6484326  0.35156742]]\n",
      "['1', '0']\n"
     ]
    }
   ],
   "source": [
    "predict_probs=cls_model.predict(is_pairs=False,dataloader=['这孩子真可爱','这人看起来像傻子似的'])\n",
    "print(predict_probs)\n",
    "id2label={id_:label for label,id_ in label2id.items()}\n",
    "predict_tags=[id2label[id_] for id_ in np.argmax(predict_probs,axis=1)]\n",
    "print(predict_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee71d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
