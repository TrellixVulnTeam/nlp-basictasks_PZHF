{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540e7f49",
   "metadata": {},
   "source": [
    "# 数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ef266",
   "metadata": {},
   "source": [
    "数据集类型是微博情感分类 \n",
    "\n",
    "来源https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/weibo_senti_100k/intro.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5e690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3cdb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/root/miniconda3/envs/nlp_sr/lib/python36.zip', '/root/miniconda3/envs/nlp_sr/lib/python3.6', '/root/miniconda3/envs/nlp_sr/lib/python3.6/lib-dynload', '/root/.local/lib/python3.6/site-packages', '/root/miniconda3/envs/nlp_sr/lib/python3.6/site-packages', '/root/miniconda3/envs/nlp_sr/lib/python3.6/site-packages/IPython/extensions', '/root/.ipython', '/root/NLP_warehouse/reconstruct/basictask']\n"
     ]
    }
   ],
   "source": [
    "module_path=os.path.abspath('/root/NLP_warehouse/reconstruct/basictask/')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ffd5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks import cls\n",
    "from evaluation import clsEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cebfab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数目（总体）：119988\n",
      "评论数目（正向）：59993\n",
      "评论数目（负向）：59995\n"
     ]
    }
   ],
   "source": [
    "data_path='../../datasets/weibo_senti/weibo_senti_100k.csv'\n",
    "pd_all = pd.read_csv(data_path)\n",
    "\n",
    "print('评论数目（总体）：%d' % pd_all.shape[0])\n",
    "print('评论数目（正向）：%d' % pd_all[pd_all.label==1].shape[0])\n",
    "print('评论数目（负向）：%d' % pd_all[pd_all.label==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc368d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107840</th>\n",
       "      <td>0</td>\n",
       "      <td>吃完饭之后吐最近都已经习惯成自然了，我真心是控制不了自己的身体了，想要怎样？！要么给个痛快，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77002</th>\n",
       "      <td>0</td>\n",
       "      <td>错过了直播回放了下春晚，多牛B的舞台，多欢乐的云迪和力宏那孩子，费大妈虽说像带个假面具但宝刀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85615</th>\n",
       "      <td>0</td>\n",
       "      <td>知道我现在多困么！可是我根本不敢睡！[抓狂][抓狂][泪][泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68304</th>\n",
       "      <td>0</td>\n",
       "      <td>转 //@王权锋:帮转！?  //@王浩908: [泪] //@360陶伟华:帮转，最恨这种...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49611</th>\n",
       "      <td>1</td>\n",
       "      <td>周四，是每个女生的幸运日[鼓掌]，当然你要点了这个链接http://t.cn/zl82S2E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>1</td>\n",
       "      <td>安贞180大退房，客人非常有秩序的自觉排队退房，2点之前所有的退房全部退完，非常给力，HOL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57780</th>\n",
       "      <td>1</td>\n",
       "      <td>#百变大咖秀第五季# 马年马上到，大白组合继续挑战“非人类”，双马贺新年了！人们说，马上能放...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48351</th>\n",
       "      <td>1</td>\n",
       "      <td>#高级定制#  cartier定制系列...18k白金的love系列手镯也是那么的被吸引.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85435</th>\n",
       "      <td>0</td>\n",
       "      <td>狠心的护士小姐?居然还是扎在了昨天输液的血管上！没有天理！还肿了[泪] 我在:http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90766</th>\n",
       "      <td>0</td>\n",
       "      <td>腹肌!!!!舔屏ing!!!!//@吉本老师求同行去夏威夷: 那?候的腹肌啊~~[抓狂]@n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45886</th>\n",
       "      <td>1</td>\n",
       "      <td>我们坐的是＂如意厅＂[哈哈] //@崔玉Nicholas:沾一下他们开业的喜气！[偷笑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109283</th>\n",
       "      <td>0</td>\n",
       "      <td>各色人等各种放假，各种羡慕嫉妒恨！[抓狂][抓狂]我什么时候开始有假？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15749</th>\n",
       "      <td>1</td>\n",
       "      <td>这周再试试[爱你] //@Jessica_卡卡:@Oh-My奥利奥 这样就不是化了的冰棍儿味...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105201</th>\n",
       "      <td>0</td>\n",
       "      <td>男花儿甲，只剩肖舒翰一人孤军奋战。决一剑惜败老山选手。孩子不易，我感动[泪][good][赞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23848</th>\n",
       "      <td>1</td>\n",
       "      <td>[爱你]一起出发吧~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104567</th>\n",
       "      <td>0</td>\n",
       "      <td>[?]//@V6家族-台?人在大?: //@李慧?: 再?[晕]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109645</th>\n",
       "      <td>0</td>\n",
       "      <td>陪一个13岁小女生看「泰迪」，突然发现很不合适！[衰][衰][衰][?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31979</th>\n",
       "      <td>1</td>\n",
       "      <td>[鼓掌]//@高铁旅游生态圈合作: 我晚上到，陪你玩转南锣。 //@无须豆蔻:哈哈哈重温学生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29251</th>\n",
       "      <td>1</td>\n",
       "      <td>老相好[嘻嘻]有???[偷笑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52604</th>\n",
       "      <td>1</td>\n",
       "      <td>我把我改进后的架子图纸给木工师傅解释半天，他听完后抽着烟，看着我好久，我想他要么是想说:这真...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                             review\n",
       "107840      0  吃完饭之后吐最近都已经习惯成自然了，我真心是控制不了自己的身体了，想要怎样？！要么给个痛快，...\n",
       "77002       0  错过了直播回放了下春晚，多牛B的舞台，多欢乐的云迪和力宏那孩子，费大妈虽说像带个假面具但宝刀...\n",
       "85615       0                   知道我现在多困么！可是我根本不敢睡！[抓狂][抓狂][泪][泪]\n",
       "68304       0  转 //@王权锋:帮转！?  //@王浩908: [泪] //@360陶伟华:帮转，最恨这种...\n",
       "49611       1  周四，是每个女生的幸运日[鼓掌]，当然你要点了这个链接http://t.cn/zl82S2E...\n",
       "1822        1  安贞180大退房，客人非常有秩序的自觉排队退房，2点之前所有的退房全部退完，非常给力，HOL...\n",
       "57780       1  #百变大咖秀第五季# 马年马上到，大白组合继续挑战“非人类”，双马贺新年了！人们说，马上能放...\n",
       "48351       1  #高级定制#  cartier定制系列...18k白金的love系列手镯也是那么的被吸引.....\n",
       "85435       0  狠心的护士小姐?居然还是扎在了昨天输液的血管上！没有天理！还肿了[泪] 我在:http://...\n",
       "90766       0  腹肌!!!!舔屏ing!!!!//@吉本老师求同行去夏威夷: 那?候的腹肌啊~~[抓狂]@n...\n",
       "45886       1       我们坐的是＂如意厅＂[哈哈] //@崔玉Nicholas:沾一下他们开业的喜气！[偷笑]\n",
       "109283      0                各色人等各种放假，各种羡慕嫉妒恨！[抓狂][抓狂]我什么时候开始有假？\n",
       "15749       1  这周再试试[爱你] //@Jessica_卡卡:@Oh-My奥利奥 这样就不是化了的冰棍儿味...\n",
       "105201      0  男花儿甲，只剩肖舒翰一人孤军奋战。决一剑惜败老山选手。孩子不易，我感动[泪][good][赞...\n",
       "23848       1                                         [爱你]一起出发吧~\n",
       "104567      0                   [?]//@V6家族-台?人在大?: //@李慧?: 再?[晕]\n",
       "109645      0               陪一个13岁小女生看「泰迪」，突然发现很不合适！[衰][衰][衰][?]\n",
       "31979       1  [鼓掌]//@高铁旅游生态圈合作: 我晚上到，陪你玩转南锣。 //@无须豆蔻:哈哈哈重温学生...\n",
       "29251       1                                    老相好[嘻嘻]有???[偷笑]\n",
       "52604       1  我把我改进后的架子图纸给木工师傅解释半天，他听完后抽着烟，看着我好久，我想他要么是想说:这真..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_all.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94faee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119988\n"
     ]
    }
   ],
   "source": [
    "from readers.cls import getExamplesFromData\n",
    "print(len(pd_all))\n",
    "random_idx=np.random.permutation(len(pd_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e976976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 20000\n"
     ]
    }
   ],
   "source": [
    "sentences=pd_all['review'].values[random_idx].tolist()[:20000]\n",
    "labels=pd_all['label'].values[random_idx].tolist()[:20000]\n",
    "print(len(sentences),len(labels))\n",
    "random_idx=np.random.permutation(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a559f866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 125 : *****************************Logging some train examples*****************************\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 126 : Total train nums is : 16000\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "荨麻疹及其汹涌的来找我，姐快Hold不住了，求良药！求良方！[泪]\t0\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "我很成功地一次又一次躲避了镜头，哈哈。@安徽荣耀 @合肥虎哥 @雒尘LC [哈哈]\t1\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "庆幸的是，咱的西红柿稳赢，我自豪！！！[嘻嘻]//@TIEasy:[鼓掌]\t1\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "@晴晴_apple @可能的世界C小窝 @m265 [泪]//@水瓶座蜜语: [抓狂]\t0\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "你们丫愿意讲[哈哈] //@二逼瓦西里:[泪][泪][泪][泪]\t0\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 125 : *****************************Logging some dev examples*****************************\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 126 : Total dev nums is : 4000\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "全没打着！ //@全球顶尖摄影:我表示中枪了[泪]\t0\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "[吃惊]这个是我什么时候传的(⊙o⊙)…大家先围观 因为这个是用的鸡脯肉，所以做出来的口感和滋味并不是很理想，后面会继续分享改进版，使用鸡腿肉做的，而且汤汁也做了改进。[嘻嘻]\t1\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "谁知道燕麦粥用什么办法能煮成像酒店那样啊？最近想喝可是做出来很失败[晕]\t0\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "#可言可语#某日，可可走进哥哥家的那栋楼，边走边用鼻子使劲嗅，然后像个大人一样说到：妈妈，这是哥哥走过的路，有好多哥哥的味道[哈哈]。可爸在一边打趣道：原来小老鼠的鼻子也这么灵敏啊？[黑线]\t1\n",
      "2021-08-14 13:27:31 - INFO - getExamplesFromData - 129 : \n",
      "#香奈儿餐厅 Beige Alain Ducasse Tokyo#这个世界几乎没有女人不迷恋香奈儿，殊不知除了优雅的时装和迷人的香水，香奈儿不但上了雪山，还下了厨房。香奈儿的餐厅隐藏在东京银座香奈儿大厦的10楼，这里请到了法国国宝级阿兰?杜卡斯，得到了“米其林二星”的加持,十分“Coco Chanel”的味道[爱你]\t1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "label2id={'0':0,'1':1}\n",
    "dev_ratio=0.2\n",
    "dev_nums=int(len(sentences)*dev_ratio)\n",
    "train_nums=len(sentences)-dev_nums\n",
    "print(dev_nums)\n",
    "train_sentences=sentences[:train_nums]\n",
    "train_labels=labels[:train_nums]\n",
    "dev_sentences=sentences[-dev_nums:]\n",
    "dev_labels=labels[-dev_nums:]\n",
    "train_examples,max_seq_len=getExamplesFromData(sentences=train_sentences,labels=train_labels,label2id=label2id,mode='train',return_max_len=True)\n",
    "dev_examples=getExamplesFromData(sentences=dev_sentences,labels=dev_labels,label2id=label2id,mode='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed96a5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8005 2066\n"
     ]
    }
   ],
   "source": [
    "print(sum(train_labels),sum(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e279b21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 13:27:31 - INFO - __init__ - 50 : The label2id is\n",
      " {\"0\": 0, \"1\": 1}\n",
      "2021-08-14 13:27:31 - INFO - __init__ - 58 : Loading model from /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/, which is from huggingface model\n",
      "2021-08-14 13:27:31 - INFO - get_config_dict - 177 : loading configuration file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/config.json\n",
      "2021-08-14 13:27:31 - INFO - from_pretrained - 404 : loading archive file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/\n",
      "2021-08-14 13:27:31 - INFO - from_pretrained - 422 : Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 13:27:32 - INFO - from_pretrained - 124 : loading vocabulary file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "model_path='/data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/'\n",
    "print(max_seq_len)\n",
    "max_seq_len=min(512,max_seq_len)\n",
    "cls_model=cls(model_path=model_path,label2id=label2id,max_seq_length=max_seq_len,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "603f5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=32\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "943fd154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 13:27:32 - INFO - __init__ - 30 : Evalautor sentence like : \n",
      "\n",
      "2021-08-14 13:27:32 - INFO - __init__ - 32 : UP！虽然你很不和谐//@风言疯语LaiN胖子：为啥你不关注别人，却要别人关注你？学名人啊？[嘻嘻] //@ponponxu：转发微博。\t1\n",
      "\n",
      "2021-08-14 13:27:32 - INFO - __init__ - 32 : @大思萌小火鸟快来啊  //@费猫猫: 下家一号举手，哈哈哈[嘻嘻] //@我家的MONKEY:这伴郎很帅嘛@大思萌小火鸟 婚礼上要看好，小心别人惦记[哈哈]\t1\n",
      "\n",
      "2021-08-14 13:27:32 - INFO - __init__ - 32 : 好感人。。[泪][泪]\t0\n",
      "\n",
      "2021-08-14 13:27:32 - INFO - __init__ - 32 : 恐怕这个公关营销方法在中国行不通吧？[衰]\t0\n",
      "\n",
      "2021-08-14 13:27:32 - INFO - __init__ - 32 : 亲们奉献手指不？ 我来试试[嘻嘻]//@陈涛carlos: [哈哈]可以试试，好玩@安妮宝贝佳丽 @艾子Gio @客家ROCK陈善宝 @吴铭rose\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator=clsEvaluator(sentences=dev_sentences,labels=dev_labels,write_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bdede3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 13:27:32 - INFO - fit - 99 : 当前是单句子分类任务\n",
      "2021-08-14 13:27:32 - INFO - fit - 110 : 一个epoch 下，每隔100个step会输出一次loss，每隔250个step会评估一次模型\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e2ccadd5544d43abaca7261fc9b084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7085e82f28b441aade517573787889b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 13:27:37 - INFO - __call__ - 48 : ClsEvaluator: Evaluating the model on  dataset in epoch 0 after 1 steps:\n",
      "2021-08-14 13:27:37 - INFO - predict - 218 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78ea3921d114f5e840a485cfc2dd363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 13:29:08 - INFO - __call__ - 55 : Accuracy: 0.532\n",
      "2021-08-14 13:29:08 - INFO - __call__ - 62 : AUC: 0.555\n",
      "2021-08-14 13:29:09 - INFO - save_pretrained - 505 : Model weights saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/pytorch_model.bin\n",
      "2021-08-14 13:29:09 - INFO - save_pretrained - 150 : Configuration saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-14 13:29:09 - INFO - save_vocab - 51 : Vocab saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-14 13:29:09 - INFO - fit - 185 : In epoch 0, training_step 0, the eval score is 0.5545516567542055, previous eval score is -9999999, model has been saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\n",
      "2021-08-14 13:35:01 - INFO - fit - 163 : Epoch : 0, train_step : 100/500, loss_value : 0.3212981130508706 \n",
      "2021-08-14 13:40:52 - INFO - fit - 163 : Epoch : 0, train_step : 200/500, loss_value : 0.06558689029654488 \n",
      "2021-08-14 13:43:50 - INFO - __call__ - 48 : ClsEvaluator: Evaluating the model on  dataset in epoch 0 after 251 steps:\n",
      "2021-08-14 13:43:50 - INFO - predict - 218 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377f1de34f694d6f97900a06eca23ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 13:45:51 - INFO - __call__ - 55 : Accuracy: 0.981\n",
      "2021-08-14 13:45:51 - INFO - __call__ - 62 : AUC: 0.998\n",
      "2021-08-14 13:45:52 - INFO - save_pretrained - 505 : Model weights saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/pytorch_model.bin\n",
      "2021-08-14 13:45:52 - INFO - save_pretrained - 150 : Configuration saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-14 13:45:52 - INFO - save_vocab - 51 : Vocab saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-14 13:45:52 - INFO - fit - 185 : In epoch 0, training_step 250, the eval score is 0.9981862748533152, previous eval score is 0.5545516567542055, model has been saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5652511f0b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NLP_warehouse/reconstruct/basictask/tasks/cls.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, is_pairs, train_dataloader, evaluator, epochs, loss_fct, scheduler, warmup_proportion, optimizer_type, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, early_stop_patience, print_loss_step, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp_sr/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp_sr/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cls_model.fit(is_pairs=False,train_dataloader=train_dataloader,evaluator=evaluator,output_path=\"/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8bbbe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 14:00:06 - INFO - __init__ - 50 : The label2id is\n",
      " {\"0\": 0, \"1\": 1}\n",
      "2021-08-14 14:00:06 - INFO - get_config_dict - 177 : loading configuration file /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-14 14:00:06 - INFO - from_pretrained - 404 : loading archive file /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT\n",
      "2021-08-14 14:00:06 - INFO - from_pretrained - 422 : Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "2021-08-14 14:00:07 - INFO - from_pretrained - 124 : loading vocabulary file /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-14 14:00:07 - INFO - __init__ - 62 : Loading model from /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model, which has been finetuned.\n"
     ]
    }
   ],
   "source": [
    "really_import=cls(model_path='/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model',\n",
    "                  label2id=label2id,max_seq_length=max_seq_len,device='cpu',is_finetune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4083534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 14:01:59 - INFO - predict - 218 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aca00260dc94134b7f1b9aff9a55961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicts=really_import.predict(is_pairs=False,dataloader=dev_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73fc604c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.981"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((np.argmax(predicts,axis=1)==np.array(dev_labels)).tolist())/len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5298f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6929bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRF(nn.Module):\n",
    "    def __init__(self, num_tags, batch_first=True, hasTraining=False) -> None:\n",
    "        super().__init__()\n",
    "        self.num_tags = num_tags\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        if hasTraining==False:\n",
    "            self.start_transitions = nn.Parameter(torch.empty(num_tags))\n",
    "            self.end_transitions = nn.Parameter(torch.empty(num_tags))\n",
    "            self.transitions = nn.Parameter(torch.empty(num_tags,num_tags))\n",
    "            self.init_matrix()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def init_matrix(self):\n",
    "        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.transitions, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c40eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf=CRF(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85e0a05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sds/dsd/ad'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"sds\",'dsd','ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed37f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=crf.transitions,f='./tmp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "539f802f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0763,  0.0966, -0.0893, -0.0571, -0.0983, -0.0413,  0.0384,  0.0052,\n",
       "          0.0677,  0.0197,  0.0469,  0.0046,  0.0783, -0.0790, -0.0673, -0.0206,\n",
       "         -0.0765, -0.0227,  0.0540, -0.0875],\n",
       "        [ 0.0077,  0.0380, -0.0522, -0.0449, -0.0687,  0.0733, -0.0563,  0.0222,\n",
       "         -0.0178, -0.0719,  0.0617, -0.0544,  0.0430,  0.0310, -0.0394, -0.0492,\n",
       "         -0.0650,  0.0193, -0.0395,  0.0256],\n",
       "        [-0.0288,  0.0377,  0.0286, -0.0850,  0.0333, -0.0450,  0.0586, -0.0283,\n",
       "         -0.0705, -0.0768, -0.0528,  0.0722, -0.0189,  0.0898,  0.0761, -0.0595,\n",
       "          0.0618,  0.0099,  0.0679,  0.0191],\n",
       "        [-0.0255, -0.0240, -0.0407,  0.0783,  0.0833,  0.0522,  0.0329, -0.0547,\n",
       "          0.0404,  0.0451,  0.0487, -0.0752, -0.0327, -0.0162, -0.0277, -0.0892,\n",
       "         -0.0172, -0.0717,  0.0907,  0.0358],\n",
       "        [-0.0634,  0.0128, -0.0769,  0.0997, -0.0183, -0.0625, -0.0745, -0.0118,\n",
       "          0.0705, -0.0982, -0.0611,  0.0490,  0.0317, -0.0486, -0.0417,  0.0550,\n",
       "          0.0839,  0.0384,  0.0402,  0.0790],\n",
       "        [-0.0486,  0.0673,  0.0849, -0.0361,  0.0567, -0.0731,  0.0538, -0.0178,\n",
       "         -0.0341,  0.0047,  0.0042, -0.0108,  0.0559, -0.0152, -0.0189, -0.0575,\n",
       "         -0.0087,  0.0078,  0.0327, -0.0684],\n",
       "        [-0.0159,  0.0467,  0.0257, -0.0955,  0.0575, -0.0840, -0.0289, -0.0315,\n",
       "          0.0163,  0.0988,  0.0474,  0.0753,  0.0835, -0.0714, -0.0879,  0.0417,\n",
       "          0.0558, -0.0340,  0.0243, -0.0287],\n",
       "        [ 0.0078,  0.0793, -0.0919,  0.0028, -0.0751,  0.0540, -0.0990, -0.0797,\n",
       "          0.0918,  0.0987,  0.0108, -0.0810, -0.0562, -0.0471, -0.0617,  0.0470,\n",
       "          0.0229,  0.0105, -0.0495,  0.0161],\n",
       "        [ 0.0715, -0.0283,  0.0087,  0.0568, -0.0100,  0.0296,  0.0057, -0.0349,\n",
       "          0.0823,  0.0490,  0.0883, -0.0211,  0.0981,  0.0081, -0.0153, -0.0751,\n",
       "         -0.0789,  0.0819,  0.0951, -0.0904],\n",
       "        [-0.0402,  0.0627, -0.0187,  0.0255, -0.0653,  0.0204,  0.0643, -0.0172,\n",
       "         -0.0320,  0.0624, -0.0170,  0.0963, -0.0314, -0.0788, -0.0895, -0.0849,\n",
       "          0.0747, -0.0555,  0.0956, -0.0364]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('./tmp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c2804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea3749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce861cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
