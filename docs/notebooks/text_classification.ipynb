{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540e7f49",
   "metadata": {},
   "source": [
    "# 数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ef266",
   "metadata": {},
   "source": [
    "数据集类型是微博情感分类 \n",
    "\n",
    "来源https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/weibo_senti_100k/intro.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab231cb",
   "metadata": {},
   "source": [
    "# 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5e690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "0.1.4\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from nlp_basictasks.tasks import cls\n",
    "from nlp_basictasks.evaluation import clsEvaluator\n",
    "from nlp_basictasks.readers.cls import getExamplesFromData\n",
    "import nlp_basictasks\n",
    "print(nlp_basictasks.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b3833",
   "metadata": {},
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cebfab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数目（总体）：119988\n",
      "评论数目（正向）：59993\n",
      "评论数目（负向）：59995\n"
     ]
    }
   ],
   "source": [
    "data_path='/data/nfs14/nfs/aisearch/asr/xhsun/datasets/weibo_senti_100k.csv'\n",
    "pd_all = pd.read_csv(data_path)\n",
    "\n",
    "print('评论数目（总体）：%d' % pd_all.shape[0])\n",
    "print('评论数目（正向）：%d' % pd_all[pd_all.label==1].shape[0])\n",
    "print('评论数目（负向）：%d' % pd_all[pd_all.label==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc368d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74624</th>\n",
       "      <td>0</td>\n",
       "      <td>苦逼了。撞车加失声，挂水还过敏。[泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98338</th>\n",
       "      <td>0</td>\n",
       "      <td>没检查到作业，百爪挠心啊[泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23380</th>\n",
       "      <td>1</td>\n",
       "      <td>回复@一朵纯白的粒子云:西藏不是天堂,天堂也有乌云,我要做和要我做,仅仅是一步之遥[哈哈] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55716</th>\n",
       "      <td>1</td>\n",
       "      <td>快出新品了哈[亲亲] //@Kaffee_Dora:看着好吃，今年就定这个? //@ebee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100619</th>\n",
       "      <td>0</td>\n",
       "      <td>咋个一阵酸楚[泪][泪] //@赵楚: 他妈的！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22351</th>\n",
       "      <td>1</td>\n",
       "      <td>Audi PR[威武],四环太有天缘了，Q3投放&amp;奥迪俱乐部杯，什么也阻挡不了，大家快来吧 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28719</th>\n",
       "      <td>1</td>\n",
       "      <td>#豆果趣事儿#[馋嘴]今天起豆果网有零食角啦！还是以进货价的一半的价格自助购买唷～亲们见到过...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58880</th>\n",
       "      <td>1</td>\n",
       "      <td>自然醒！早[可爱]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75755</th>\n",
       "      <td>0</td>\n",
       "      <td>//@frank7383: //@W天之蓝W:这个总统应该上断头台[怒] //@frank7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50973</th>\n",
       "      <td>1</td>\n",
       "      <td>记得小时候被人欺负了，我就在家里磨菜刀，并豪言：谁尼玛再欺负我，我非剁了他！ //@长话短说...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109541</th>\n",
       "      <td>0</td>\n",
       "      <td>回复@北京堵车么:政府也该11路！带头绿色！ //@北京堵车么:政府让咱绿色出行！11路走起...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32100</th>\n",
       "      <td>1</td>\n",
       "      <td>妹子你前途无量[哈哈] //@杨哏儿:刚刚忘了艾特人了 再来 祝空空大大夜夜都和吴彦祖来一发...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46545</th>\n",
       "      <td>1</td>\n",
       "      <td>晚安，Sponge Ashin[爱你]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85011</th>\n",
       "      <td>0</td>\n",
       "      <td>早起到报社开始年会彩排，下午顺利结束；晚上还赶场参加朋友公司的年终媒体聚会，刚刚才进家门，累...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50475</th>\n",
       "      <td>1</td>\n",
       "      <td>城管。[哈哈]//@宁财神:这……</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51145</th>\n",
       "      <td>1</td>\n",
       "      <td>是啊，骑行在画中，别有一番味道。 //@51book陈鹏:回复 @同程网吴志祥:苏州是骑行的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68412</th>\n",
       "      <td>0</td>\n",
       "      <td>回复@少年梁小博的奇幻漂流:不够累，就不要无病呻吟，睡眠是奢侈的。[酷][酷]//@少年梁小...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88065</th>\n",
       "      <td>0</td>\n",
       "      <td>[怒]//@微博同城会: 上午10点左右，南京发生枪击抢劫，被抢者头部中枪当场身亡，20万现...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93675</th>\n",
       "      <td>0</td>\n",
       "      <td>[泪]//@段郎说事:九江也一样：重度污染</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>1</td>\n",
       "      <td>@王可以Kimi @开心Tingting @小粽子?? 发福利了啊~//@Debra_JUL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                             review\n",
       "74624       0                                苦逼了。撞车加失声，挂水还过敏。[泪]\n",
       "98338       0                                    没检查到作业，百爪挠心啊[泪]\n",
       "23380       1  回复@一朵纯白的粒子云:西藏不是天堂,天堂也有乌云,我要做和要我做,仅仅是一步之遥[哈哈] ...\n",
       "55716       1  快出新品了哈[亲亲] //@Kaffee_Dora:看着好吃，今年就定这个? //@ebee...\n",
       "100619      0                           咋个一阵酸楚[泪][泪] //@赵楚: 他妈的！\n",
       "22351       1  Audi PR[威武],四环太有天缘了，Q3投放&奥迪俱乐部杯，什么也阻挡不了，大家快来吧 ...\n",
       "28719       1  #豆果趣事儿#[馋嘴]今天起豆果网有零食角啦！还是以进货价的一半的价格自助购买唷～亲们见到过...\n",
       "58880       1                                          自然醒！早[可爱]\n",
       "75755       0  //@frank7383: //@W天之蓝W:这个总统应该上断头台[怒] //@frank7...\n",
       "50973       1  记得小时候被人欺负了，我就在家里磨菜刀，并豪言：谁尼玛再欺负我，我非剁了他！ //@长话短说...\n",
       "109541      0  回复@北京堵车么:政府也该11路！带头绿色！ //@北京堵车么:政府让咱绿色出行！11路走起...\n",
       "32100       1  妹子你前途无量[哈哈] //@杨哏儿:刚刚忘了艾特人了 再来 祝空空大大夜夜都和吴彦祖来一发...\n",
       "46545       1                                晚安，Sponge Ashin[爱你]\n",
       "85011       0  早起到报社开始年会彩排，下午顺利结束；晚上还赶场参加朋友公司的年终媒体聚会，刚刚才进家门，累...\n",
       "50475       1                                  城管。[哈哈]//@宁财神:这……\n",
       "51145       1  是啊，骑行在画中，别有一番味道。 //@51book陈鹏:回复 @同程网吴志祥:苏州是骑行的...\n",
       "68412       0  回复@少年梁小博的奇幻漂流:不够累，就不要无病呻吟，睡眠是奢侈的。[酷][酷]//@少年梁小...\n",
       "88065       0  [怒]//@微博同城会: 上午10点左右，南京发生枪击抢劫，被抢者头部中枪当场身亡，20万现...\n",
       "93675       0                              [泪]//@段郎说事:九江也一样：重度污染\n",
       "6359        1  @王可以Kimi @开心Tingting @小粽子?? 发福利了啊~//@Debra_JUL..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_all.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f878a71",
   "metadata": {},
   "source": [
    "## 打乱数据集，同时划分训练、验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94faee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119988\n"
     ]
    }
   ],
   "source": [
    "print(len(pd_all))\n",
    "random_idx=np.random.permutation(len(pd_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e976976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 20000\n"
     ]
    }
   ],
   "source": [
    "#时间关系仅取前20000个作为训练\n",
    "sentences=pd_all['review'].values[random_idx].tolist()[:20000]\n",
    "labels=pd_all['label'].values[random_idx].tolist()[:20000]\n",
    "print(len(sentences),len(labels))\n",
    "random_idx=np.random.permutation(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a559f866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 128 : *****************************Logging some train examples*****************************\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 129 : Total train nums is : 16000\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "//@神笔记:把人快折腾残废了，1000多块就了事？[怒]\t0\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "#五月专属优惠#即日起，关注咖啡馆微信，点很多人的任一种类?饭就送价值23元蜂蜜柚子茶一杯哦，超值套餐巨划算！[太开心] 仅限现金消费~\t1\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "//@诗人潘婷: 这畜生！绝对嚣张不止一日了！为何会长期呆在警察的队伍里？[怒]//@陈明远微博:[怒]//@徐昕: [怒]//@声音法治周刊:[怒]现在的土匪……//@周永坤微博:警察开枪就为了耍威风？\t0\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "[泪][泪] //@丛中笑327:[偷笑] //@徐巍:一样一样的[偷笑] //@王潮歌:我马上给孩子他爸看了！\t0\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "我手机满屏了等我清理一下 //@day11: 姑娘 你太神了！[good]我昨天爱拍得里下了五篇民宿介绍占了2个多G……我们去台湾用3G网嗖嗖的下！[偷笑] 转给爱疯小王子他媳妇 @michelle75005 还有爱疯小王子本人@land浪摄流   [哈哈][哈哈]各取所需吧！\t1\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 128 : *****************************Logging some dev examples*****************************\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 129 : Total dev nums is : 4000\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "[鄙视]//@懒骆驼: 基情澎湃啊，可惜距离太远，只能撸了。 //@叁魂不见柒魄:一打?，居然是?情?，?屎我了。 //@风惹尘埃: 是够吵的，爱特来爱特去，好累的[哈哈][哈哈][哈哈][哈哈] //@87年柿子:?…私聊一边去[衰]欧洲杯将是中国队问鼎\t1\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "[泪]说滴好啊！！！//@时尚热门榜中榜: 有钱，不可能养你一辈子\t0\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "回复@权金城韩国烧烤:@陈玉霞博斐秀禾 @瑷羽小姐 @阿誉菜品设计总监 @贝太食品造型师健伟 @鼎好韩震 @崇文老王 //@权金城韩国烧烤:给力活动一波接一波啊！亲们加油啊~~手机会有的，肉肉也会有的，哇哈哈~~[嘻嘻]@宋岩Q_Q @百合的泪一金花 @熊丽电台 @陌白渺渺 @纪春月 @勤劳的工作狂 @彭涌_爱美食\t1\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "哦，还有这说法的啦，我吃的也是泡饭就鱼冻冻萝卜干。[嘻嘻]\t1\n",
      "2021-08-25 18:11:32 - INFO - getExamplesFromData - 132 : \n",
      "早上她讹我，说我昨晚说梦话喊了一个人的名字。[失望]\t0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "label2id={'0':0,'1':1}\n",
    "dev_ratio=0.2#训练集的20%作为验证\n",
    "dev_nums=int(len(sentences)*dev_ratio)\n",
    "train_nums=len(sentences)-dev_nums\n",
    "print(dev_nums)\n",
    "train_sentences=sentences[:train_nums]\n",
    "train_labels=labels[:train_nums]\n",
    "dev_sentences=sentences[-dev_nums:]\n",
    "dev_labels=labels[-dev_nums:]\n",
    "train_examples,max_seq_len=getExamplesFromData(sentences=train_sentences,labels=train_labels,label2id=label2id,mode='train',return_max_len=True)\n",
    "dev_examples=getExamplesFromData(sentences=dev_sentences,labels=dev_labels,label2id=label2id,mode='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c3b1414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<nlp_basictasks.readers.cls.InputExample at 0x7f489ee340a0>,\n",
       " <nlp_basictasks.readers.cls.InputExample at 0x7f489ee34220>,\n",
       " <nlp_basictasks.readers.cls.InputExample at 0x7f489ee342b0>,\n",
       " <nlp_basictasks.readers.cls.InputExample at 0x7f489ee34310>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ac4b5",
   "metadata": {},
   "source": [
    "# 定义路径加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e279b21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:43:49 - INFO - __init__ - 48 : The label2id is\n",
      " {\"0\": 0, \"1\": 1}\n",
      "2021-08-24 19:43:49 - INFO - __init__ - 58 : Loading model from /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/, which is from huggingface model\n",
      "2021-08-24 19:43:49 - INFO - get_config_dict - 177 : loading configuration file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/config.json\n",
      "2021-08-24 19:43:49 - INFO - from_pretrained - 404 : loading bert model file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/\n",
      "2021-08-24 19:43:49 - INFO - from_pretrained - 423 : BertConfig has been loaded from /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:43:51 - INFO - from_pretrained - 125 : loading vocabulary file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "#max_seq_len就是训练集中最长的句子长度\n",
    "model_path='/data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/'\n",
    "print(max_seq_len)\n",
    "max_seq_len=min(512,max_seq_len)\n",
    "cls_model=cls(model_path=model_path,label2id=label2id,max_seq_length=max_seq_len,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603f5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=32\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874b617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c28b9f49",
   "metadata": {},
   "source": [
    "# 定义evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943fd154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:44:28 - INFO - __init__ - 28 : label2id like : {'0': 0, '1': 1}\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 39 : The number of 0 in dataset is 2020\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 39 : The number of 1 in dataset is 1980\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 45 : Evalautor sentence like : \n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : [衰] //@中原网:【图片中的“海市蜃楼”系周边建筑】有结果啦，虚惊一场，有多位网友向小编反映，下午的时候这个点经过该路口，并未发现有“海市蜃楼”现象出现，图片上的“海市蜃楼”应该是对面的建筑（经现场核实，系附近一楼盘）反射在玻璃板上，正好被拍下来了，拍摄者当时可能坐在公交车里拍的。\t0\n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : @一辰 ，尼玛太有才了[cai正呀] [哈哈] @隋杨\t1\n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : 小伙伴儿们现在拿起手机，打开微博客户端-广场，双节有惊喜呦！[吃元宵][moc亲吻]//@兰亦兰: [蜡烛][泪]//@我不是蛐蛐: [哈哈] //@郭宏:转发微博\t1\n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : 我们饮中八仙也郑重承诺 剩下的画展 我们必须都去 哈哈//@大匠之门李笑天: 回复@八年小散:我郑重诚诺。要在中国美术办它10次画展[嘻嘻][嘻嘻] //@八年小散:还有听见此话的吗？ //@大匠之门李笑天:[嘻嘻][嘻嘻][威武] //@郭月晨:这个我听见了 //@苗雪珊: [可爱]真滴嘛\t1\n",
      "\n",
      "2021-08-24 19:44:28 - INFO - __init__ - 47 : [蜡烛][蜡烛][蜡烛]求报复社会的人们放过无辜老百姓吧[伤心][伤心][伤心]\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator=clsEvaluator(sentences=dev_sentences,label_ids=dev_labels,write_csv=False,label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e98e64",
   "metadata": {},
   "source": [
    "# 训练模型\n",
    "- is_pairs用来指明是单句子分类任务还是双句子分类任务\n",
    "- output_path是保存模型的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdede3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:45:35 - INFO - fit - 102 : 当前是单句子分类任务\n",
      "2021-08-24 19:45:35 - INFO - fit - 113 : 一个epoch 下，每隔100个step会输出一次loss，每隔250个step会评估一次模型\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20bc0be763d4e89be784039cd6de085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0433a587b05449d28fe61990f29604df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:45:43 - INFO - __call__ - 63 : ClsEvaluator: Evaluating the model on  dataset in epoch 0 after 1 steps:\n",
      "2021-08-24 19:45:43 - INFO - predict - 221 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45353ed454b141ef93c78171118a053c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:49:18 - INFO - __call__ - 70 : Accuracy: 0.436\n",
      "2021-08-24 19:49:18 - INFO - __call__ - 82 : 0\tprecision : 0.450293, recall : 0.529205,  f1 score : 0.481653\n",
      "2021-08-24 19:49:18 - INFO - __call__ - 82 : 1\tprecision : 0.415127, recall : 0.340907,  f1 score : 0.369487\n",
      "2021-08-24 19:49:18 - INFO - __call__ - 93 : AUC: 0.404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:49:20 - INFO - save_pretrained - 509 : Model weights saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/pytorch_model.bin\n",
      "2021-08-24 19:49:20 - INFO - save_pretrained - 150 : Configuration saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-24 19:49:20 - INFO - save_vocab - 51 : Vocab saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-24 19:49:20 - INFO - fit - 188 : In epoch 0, training_step 0, the eval score is 0.403772502250225, previous eval score is -9999999, model has been saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\n",
      "2021-08-24 20:00:12 - INFO - fit - 166 : Epoch : 0, train_step : 100/500, loss_value : 0.341104484423995 \n",
      "2021-08-24 20:10:16 - INFO - fit - 166 : Epoch : 0, train_step : 200/500, loss_value : 0.06391732832184062 \n",
      "2021-08-24 20:15:35 - INFO - __call__ - 63 : ClsEvaluator: Evaluating the model on  dataset in epoch 0 after 251 steps:\n",
      "2021-08-24 20:15:35 - INFO - predict - 221 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc071c9f33842c691c4685d5de602cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 20:18:48 - INFO - __call__ - 70 : Accuracy: 0.981\n",
      "2021-08-24 20:18:48 - INFO - __call__ - 82 : 0\tprecision : 0.965529, recall : 0.998510,  f1 score : 0.976769\n",
      "2021-08-24 20:18:48 - INFO - __call__ - 82 : 1\tprecision : 0.998425, recall : 0.963631,  f1 score : 0.975747\n",
      "2021-08-24 20:18:48 - INFO - __call__ - 93 : AUC: 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 20:18:55 - INFO - save_pretrained - 509 : Model weights saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/pytorch_model.bin\n",
      "2021-08-24 20:18:55 - INFO - save_pretrained - 150 : Configuration saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-24 20:18:55 - INFO - save_vocab - 51 : Vocab saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-24 20:18:55 - INFO - fit - 188 : In epoch 0, training_step 250, the eval score is 0.9983108310831084, previous eval score is 0.403772502250225, model has been saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\n",
      "2021-08-24 20:23:54 - INFO - fit - 166 : Epoch : 0, train_step : 300/500, loss_value : 0.04959781204350293 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5652511f0b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/tasks/cls.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, is_pairs, train_dataloader, evaluator, epochs, loss_fct, scheduler, warmup_proportion, optimizer_type, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, early_stop_patience, print_loss_step, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mskip_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mscale_before_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                     \u001b[0mloss_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#CrossEntropyLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mtraining_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/heads/cls.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, label_ids, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         '''\n\u001b[0;32m---> 97\u001b[0;31m         (sequence_outputs,pooled_output)=self.bert(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     98\u001b[0m                                                   \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                                                    \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/modules/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         encoded_layers = self.encoder(embedding_output,\n\u001b[0m\u001b[1;32m    586\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                                       output_all_encoded_layers=output_all_encoded_layers)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/modules/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/modules/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/nlp_basictasks/modules/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cls_model.fit(is_pairs=False,train_dataloader=train_dataloader,evaluator=evaluator,output_path=\"/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255a9cd",
   "metadata": {},
   "source": [
    "**时间关系暂停训练**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad830e",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6ad4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 20:29:10 - INFO - predict - 221 : 当前是单句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236f27bac0074547b393155825eda7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.00504928 0.9949508 ]\n",
      " [0.6484326  0.35156742]]\n",
      "['1', '0']\n"
     ]
    }
   ],
   "source": [
    "predict_probs=cls_model.predict(is_pairs=False,dataloader=['这孩子真可爱','这人看起来像傻子似的'])\n",
    "print(predict_probs)\n",
    "id2label={id_:label for label,id_ in label2id.items()}\n",
    "predict_tags=[id2label[id_] for id_ in np.argmax(predict_probs,axis=1)]\n",
    "print(predict_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee71d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
