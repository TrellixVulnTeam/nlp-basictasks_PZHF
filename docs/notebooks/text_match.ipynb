{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27abc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520e561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/root/miniconda3/envs/nlp_sr/lib/python36.zip', '/root/miniconda3/envs/nlp_sr/lib/python3.6', '/root/miniconda3/envs/nlp_sr/lib/python3.6/lib-dynload', '/root/.local/lib/python3.6/site-packages', '/root/miniconda3/envs/nlp_sr/lib/python3.6/site-packages', '/root/miniconda3/envs/nlp_sr/lib/python3.6/site-packages/IPython/extensions', '/root/.ipython', '/root/NLP_warehouse/reconstruct/basictask']\n"
     ]
    }
   ],
   "source": [
    "module_path=os.path.abspath('/root/NLP_warehouse/reconstruct/basictask/')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91af3b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from tasks import cls\n",
    "from evaluation import pairclsEvaluator\n",
    "from readers.paircls import getExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b122f471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 10:43:13 - INFO - getExamples - 109 : Heads like : text_a\ttext_b\tlabel\n",
      "\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 116 : *****************************Logging some train examples*****************************\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 117 : Total train nums is : 238766\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 什么牌子的米粉好？\t什么牌子的米粉好\t1\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 形容叫人忘了我的词语\t我老做梦，梦到僵尸。怎么办\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 您可以点击查看一下。\t亲您可以点击账户通然后删除一下银行卡就可以的\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 辽宁省北票市属于朝阳哪个区\t辽宁省营口市欢心甸属于哪个区\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 部落冲突怎么刷宝石\t唱吧刷金币怎么刷\t0\n"
     ]
    }
   ],
   "source": [
    "data_folder='../../datasets/lcqmc'\n",
    "label2id={\"0\":0,\"1\":1}\n",
    "train_examples=getExamples(os.path.join(data_folder,'lcqmc_train.tsv'),label2id=label2id,filter_heads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c599160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 10:43:14 - INFO - getExamples - 109 : Heads like : text_a\ttext_b\tlabel\n",
      "\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 116 : *****************************Logging some dev examples*****************************\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 117 : Total dev nums is : 8802\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 网络的镁铝是什么意思\t这个网络是什么意思\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 谁帮我注册个韩服跑跑卡丁车账号密码\t谁能帮我注册韩服跑跑卡丁车啊\t1\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 三桥东属于西安的哪个区？\t上海有哪些区？哪个区最繁华？\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 形成日地距离适中的原因是什么?\t日地距离是如何测出的？\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 爱情骗了你爱情骗了我是什么歌\t我的微信上不去了，不知道怎么了\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 109 : Heads like : text_a\ttext_b\tlabel\n",
      "\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 116 : *****************************Logging some test examples*****************************\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 117 : Total test nums is : 12500\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 支付宝密码忘记要怎么找回\t支付宝密码忘记怎么找回急\t1\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 请问这个杯子是什么牌子？\t请问这杯子是什么牌子\t1\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 领字的形旁和声旁是什么\t这些的形旁和声旁各是什么\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 谨遵教诲什么意思\t教诲是什么意思\t0\n",
      "2021-08-17 10:43:14 - INFO - getExamples - 120 : 男人为什么喜欢咬女人奶\t男人为什么喜欢玩女人的奶子\t1\n"
     ]
    }
   ],
   "source": [
    "dev_examples=getExamples(os.path.join(data_folder,'lcqmc_dev.tsv'),label2id=label2id,filter_heads=True,mode='dev')\n",
    "test_examples=getExamples(os.path.join(data_folder,'lcqmc_test.tsv'),label2id=label2id,filter_heads=True,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac832ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 10:43:14 - INFO - __init__ - 48 : The label2id is\n",
      " {\"0\": 0, \"1\": 1}\n",
      "2021-08-17 10:43:14 - INFO - __init__ - 58 : Loading model from /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/, which is from huggingface model\n",
      "2021-08-17 10:43:14 - INFO - get_config_dict - 177 : loading configuration file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/config.json\n",
      "2021-08-17 10:43:14 - INFO - from_pretrained - 404 : loading bert model file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/\n",
      "2021-08-17 10:43:14 - INFO - from_pretrained - 423 : BertConfig has been loaded from /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/config.json\n",
      "2021-08-17 10:43:16 - INFO - from_pretrained - 124 : loading vocabulary file /data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "model_path='/data/nfs14/nfs/aisearch/asr/xhsun/CommonModel/chinese-roberta-wwm/'\n",
    "paircls_model=cls(model_path=model_path,label2id=label2id,is_finetune=False,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a833ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=32\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc3d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences=[example.text_list for example in dev_examples]\n",
    "dev_labels=[example.label for example in dev_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1e24522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['开初婚未育证明怎么弄？', '初婚未育情况证明怎么开？'] 1\n"
     ]
    }
   ],
   "source": [
    "print(dev_sentences[0],dev_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a305ba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 10:43:16 - INFO - __init__ - 29 : Evalautor sentence like : \n",
      "\n",
      "2021-08-17 10:43:16 - INFO - __init__ - 31 : 开初婚未育证明怎么弄？\t初婚未育情况证明怎么开？\t1\n",
      "\n",
      "2021-08-17 10:43:16 - INFO - __init__ - 31 : 谁知道她是网络美女吗？\t爱情这杯酒谁喝都会醉是什么歌\t0\n",
      "\n",
      "2021-08-17 10:43:16 - INFO - __init__ - 31 : 人和畜生的区别是什么？\t人与畜生的区别是什么！\t1\n",
      "\n",
      "2021-08-17 10:43:16 - INFO - __init__ - 31 : 男孩喝女孩的尿的故事\t怎样才知道是生男孩还是女孩\t0\n",
      "\n",
      "2021-08-17 10:43:16 - INFO - __init__ - 31 : 这种图片是用什么软件制作的？\t这种图片制作是用什么软件呢？\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator=pairclsEvaluator(sentences_list=dev_sentences,labels=dev_labels,write_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bce5f8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 10:43:16 - INFO - fit - 104 : 当前是双句子分类任务\n",
      "2021-08-17 10:43:16 - INFO - fit - 112 : 一个epoch 下，每隔1492个step会输出一次loss，每隔3731个step会评估一次模型\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cef4a04444488ab8177585943317ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222d67224f0648a9b917abd8bedc664e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 10:43:19 - INFO - __call__ - 47 : pairclsEvaluator: Evaluating the model on  dataset in epoch 0 after 1 steps:\n",
      "2021-08-17 10:43:19 - INFO - predict - 223 : 当前是双句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af4f8e1901445f1a6510b8977318e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 10:44:53 - INFO - __call__ - 54 : Accuracy: 0.493\n",
      "2021-08-17 10:44:53 - INFO - __call__ - 61 : AUC: 0.491\n",
      "2021-08-17 10:44:54 - INFO - save_pretrained - 509 : Model weights saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/pytorch_model.bin\n",
      "2021-08-17 10:44:54 - INFO - save_pretrained - 150 : Configuration saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-17 10:44:54 - INFO - save_vocab - 51 : Vocab saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-17 10:44:54 - INFO - fit - 187 : In epoch 0, training_step 0, the eval score is 0.490856635413655, previous eval score is -9999999, model has been saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\n",
      "2021-08-17 11:22:15 - INFO - fit - 165 : Epoch : 0, train_step : 1492/37310, loss_value : 0.3796851287468589 \n",
      "2021-08-17 12:00:48 - INFO - fit - 165 : Epoch : 0, train_step : 2984/37310, loss_value : 0.23639671422601066 \n",
      "2021-08-17 12:16:35 - INFO - __call__ - 47 : pairclsEvaluator: Evaluating the model on  dataset in epoch 0 after 3732 steps:\n",
      "2021-08-17 12:16:35 - INFO - predict - 223 : 当前是双句子分类任务预测\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d842c233c724ac0bbf37a8e769b445f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 12:17:47 - INFO - __call__ - 54 : Accuracy: 0.837\n",
      "2021-08-17 12:17:47 - INFO - __call__ - 61 : AUC: 0.921\n",
      "2021-08-17 12:17:48 - INFO - save_pretrained - 509 : Model weights saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/pytorch_model.bin\n",
      "2021-08-17 12:17:48 - INFO - save_pretrained - 150 : Configuration saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/config.json\n",
      "2021-08-17 12:17:48 - INFO - save_vocab - 51 : Vocab saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/BERT/vocab.txt\n",
      "2021-08-17 12:17:48 - INFO - fit - 187 : In epoch 0, training_step 3731, the eval score is 0.920537952790054, previous eval score is 0.490856635413655, model has been saved in /data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d692db660d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m paircls_model.fit(is_pairs=True,train_dataloader=train_dataloader,evaluator=evaluator,epochs=5,\n\u001b[0;32m----> 2\u001b[0;31m                   output_path='/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/')\n\u001b[0m",
      "\u001b[0;32m~/NLP_warehouse/reconstruct/basictask/tasks/cls.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, is_pairs, train_dataloader, evaluator, epochs, loss_fct, scheduler, warmup_proportion, optimizer_type, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, early_stop_patience, print_loss_step, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                     \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp_sr/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp_sr/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paircls_model.fit(is_pairs=True,train_dataloader=train_dataloader,evaluator=evaluator,epochs=5,\n",
    "                  output_path='/data/nfs14/nfs/aisearch/asr/xhsun/tmp_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd73ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
